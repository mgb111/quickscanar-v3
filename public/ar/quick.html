<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <title>QuickScan AR Experience</title>
    <style>
      body {
        margin: 0;
        padding: 0;
        width: 100vw;
        height: 100vh;
        overflow: hidden;
        background: #000;
      }
      a-scene {
        width: 100vw;
        height: 100vh;
      }
    </style>
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>
  </head>
  <body>
    <a-scene
      mindar-image="imageTargetSrc: /uploads/demo-marker.mind; filterBeta: 0.001; filterMinCF: 0.0001; warmupTolerance: 5; missTolerance: 5"
      color-space="sRGB"
      renderer="colorManagement: true, physicallyCorrectLights"
      vr-mode-ui="enabled: false"
      device-orientation-permission-ui="enabled: false"
      embedded
      loading-screen="enabled: false"
    >
      <a-assets>
        <video
          id="videoTexture"
          src="https://www.w3schools.com/html/mov_bbb.mp4"
          loop
          muted
          playsinline
          crossorigin="anonymous"
          preload="auto"
        ></video>
      </a-assets>

      <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

      <a-entity mindar-image-target="targetIndex: 0" id="target">
        <a-video
          id="videoPlane"
          src="#videoTexture"
          width="1"
          height="1"
          position="0 0 0.01"
          visible="false"
        ></a-video>
      </a-entity>
    </a-scene>

    <script>
      document.addEventListener("DOMContentLoaded", () => {
        console.log("QuickScan AR loaded");
        
        const video = document.querySelector("#videoTexture");
        const videoPlane = document.querySelector("#videoPlane");
        const target = document.querySelector("#target");
        const scene = document.querySelector("a-scene");
        
        // Function to update video plane dimensions based on video aspect ratio
        function updateVideoAspectRatio() {
          if (video && videoPlane && video.videoWidth && video.videoHeight) {
            let videoWidth = video.videoWidth;
            let videoHeight = video.videoHeight;
            
            // Automatically detect if video is portrait (height > width)
            const isPortrait = video.videoHeight > video.videoWidth;
            
            if (isPortrait) {
              // For portrait videos, rotate the plane 90 degrees and swap dimensions for scaling
              videoPlane.setAttribute('rotation', '90 0 0');
              [videoWidth, videoHeight] = [videoHeight, videoWidth]; // Swap for aspect ratio calculation
              console.log('Portrait video detected, applying rotation and dimension swap.');
            } else {
              // For landscape videos, no rotation needed
              videoPlane.setAttribute('rotation', '0 0 0');
              console.log('Landscape video detected, no rotation applied.');
            }

            const aspectRatio = videoWidth / videoHeight;

            let scaleX, scaleY;

            if (aspectRatio < 1) {
              // Portrait video (height > width)
              scaleX = aspectRatio;
              scaleY = 1;
            } else {
              // Landscape video (width >= height)
              scaleX = 1;
              scaleY = 1 / aspectRatio;
            }

            // Use scale instead of width/height attributes
            videoPlane.object3D.scale.set(scaleX, scaleY, 1);

            console.log(`Effective video dimensions: ${videoWidth}x${videoHeight}`);
            console.log(`Aspect ratio: ${aspectRatio}`);
            console.log(`Video plane scale: ${scaleX}x${scaleY}`);
          } else {
            console.log('Video metadata not ready yet');
          }
        }
        
        // Multiple event listeners to ensure we catch the video metadata
        if (video) {
        // 'loadedmetadata' is all you need.
        video.addEventListener('loadedmetadata', updateVideoAspectRatio);
      }
        
        if (scene) {
          scene.addEventListener("loaded", () => {
            console.log("AR Scene loaded successfully");
          });
          
          scene.addEventListener("renderstart", () => {
            console.log("AR rendering started");
          });
        }
        
        // Add debug logging for target events
        let isTargetFound = false;
        
        if (target) {
          target.addEventListener("targetFound", () => {
          console.log("Target found");
          video.currentTime = 0;
          video.play().catch(e => console.error("Video play error:", e));
          videoPlane.setAttribute('visible', true);
        });
        
        target.addEventListener("targetLost", () => {
          console.log("Target lost");
          video.pause();
          videoPlane.setAttribute('visible', false);
        });
        
        
        // Request camera permissions explicitly
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
          navigator.mediaDevices.getUserMedia({ video: true })
            .then(() => {
              console.log("Camera permission granted");
            })
            .catch((error) => {
              console.error("Camera permission denied:", error);
            });
        }
      });
    </script>
  </body>
</html>
